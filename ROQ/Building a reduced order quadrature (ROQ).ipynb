{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "solar_mass_in_seconds = 4.92686088e-6\n",
    "\n",
    "def phase(f, Mc):\n",
    "\n",
    "        phase = -np.pi/4. + ( 3./( 128. * pow(Mc*np.pi*f, 5./3.) ) )\n",
    "        return phase\n",
    "\n",
    "def htilde(f, Mc):\n",
    "        Mc *= solar_mass_in_seconds\n",
    "        htilde = pow(f, -7./6.) * pow(Mc,5./6.) * np.exp(1j*phase(f,Mc))\n",
    "        return htilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this note I will show how we use the empirical interpolant of a function to make a \"reduced order quadrature\" (ROQ). The exercise is to compute the inner product between a data set d (which plays the role of $A(x,y)$ in the coupling constant work) and the function h. The standard inner product is:\n",
    "\\begin{equation}\n",
    "\\langle\\, d | h(M_c)\\, \\rangle = \\Re \\Delta f \\sum_{i=1}^{N}\\,d^{*}(f_{min} + i \\Delta f)\\,h(M_c;f_{min} +i \\Delta f)\\,,\n",
    "\\end{equation}\n",
    "In this quadrature rule there are N terms. In general N is the number of sample points of the discretely sampled data and function h and could be very large for some problems. If we substitute the empirical interpolant of h into the above equation for the inner product then we get the ROQ. To recap, the empirical interpolant of h is\n",
    "\\begin{equation} \n",
    "\\mathcal{I}[h](M_c;f) = \\sum_{j=1}^m B_j (f) h(M_c;F_j)\n",
    "\\end{equation}\n",
    "and in the previous note we computed $\\{B_j\\}_{i=1}^{n}$ and $\\{F_j\\}_{i=1}^{n}$. Substituting the empirical interpolant for h in the inner product we get \n",
    "\\begin{equation}\n",
    "\\langle\\,d | \\mathcal{I}[h]\\,\\rangle = \\Re \\Delta f\\,\\sum_{j=1}^{m}\\sum_{i=1}^{N} d^{*}(f_{min} + i \\Delta f) B_j(f_{min} + i \\Delta f) h(M_c;F_j)\\,.\n",
    "\\end{equation}\n",
    "Notice that the sum over frequency now decouples from the dependence on $M_c$! Thus we can do all the sums over frequency once-and-for-all, and evaluating the inner product should be cheaper. Thus we write the reduced order quadrature for the inner product as\n",
    "\\begin{equation}\n",
    "\\langle\\, d | h(M_c)\\, \\rangle_{\\mathrm{ROQ}} = \\Re \\sum_{j=1}^{m}\\,w_j\\,h(M_c;F_j)\\,,\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "w_j = \\Delta f\\sum_{i=1}^{N} d^{*}(f_{min} + i \\Delta f) B_j(f_{min} + i \\Delta f)\\,.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the ROQ has only m terms in the sum, whereas the original had N. Thus we get a compression of N/m. For this specific problem, the original waveforms which we built the bases for had N=5000 samples. The number of bases is around m=300, so in this case we should expect a compression of N/m = 5000/300 = 17. Let's try it out.\n",
    "\n",
    "First I'll create a data set. It doesn't matter what it is, so I'll just let it be a random vector of length 5000. I'll start by loading in the frequency series and frequency steps $\\Delta f$, and then generate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fseries = np.loadtxt(\"fseries.dat\")\n",
    "df = np.loadtxt(\"df.dat\")\n",
    "\n",
    "data = np.random.rand(len(fseries)) + 1j*np.random.rand(len(fseries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll load in the $B_j$s and the empirical interpolation nodes $F_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B_re = np.loadtxt(\"B_re.dat\")\n",
    "B_im = np.loadtxt(\"B_im.dat\")\n",
    "\n",
    "B = B_re + 1j*B_im\n",
    "\n",
    "nodes = np.loadtxt(\"nodes.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have everything I need to make the weights $\\omega_j$ which is done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# multipy data by \\Delta f\n",
    "data *= df\n",
    "\n",
    "weights = np.inner(B, data.conjugate().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll compute the regular inner product and the ROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular inner product = 5.805838449180775e-07\n",
      "ROQ = 5.805838449179256e-07\n"
     ]
    }
   ],
   "source": [
    "d_dot_h = np.vdot(data, htilde(fseries, 1.5)).real # regular inner product\n",
    "\n",
    "ROQ = np.dot(weights, htilde(nodes, 1.5)).real # ROQ inner product\n",
    "\n",
    "print \"regular inner product = %.15e\"%d_dot_h\n",
    "print \"ROQ = %.15e\"%ROQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the ROQ is essentially error free at round off. Next I'll time the regular inner product and the ROQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular inner product took 0.000582 s\n",
      "ROQ took 0.000068 s\n",
      "speedup = 8.501153\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "Mc = 2\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(50000):\n",
    "    np.vdot(data, htilde(fseries, Mc)).real # regular inner product\n",
    "e1 = time.time()\n",
    "\n",
    "t2 = time.time()\n",
    "for i in range(50000):\n",
    "    np.dot(weights, htilde(nodes, Mc)).real # ROQ inner product\n",
    "e2 = time.time()\n",
    "\n",
    "print \"regular inner product took %f s\"%((e1-t1)/50000.)\n",
    "print \"ROQ took %f s\"%((e2-t2)/50000.)\n",
    "print \"speedup = %f\"%((e1-t1) / (e2-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to give a speed up between 8 and 9, which isn't quite the predicted speed up of 16: presumably there is some overhead in passing the vectors to np.vdot and np.dot which is on the order of the time it takes to compute the inner products. Anyway, hopefully this illustrates the main point which is that if you have an empirical interpolant then computing inner products of the kind we considered can be significantly sped up. This is what we should do for the coupling coefficient work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
